{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0265a124-87b8-4d00-a464-a43292974a65",
   "metadata": {},
   "source": [
    "# Quarterly Census of Employment and Wages (QCEW) Data Importer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec248bf1-54ee-40c7-8302-501b5e753630",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df1258-4c7a-4f1a-b183-05a28a9efbdf",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is designed to automate the retrieval and processing of the Quarterly Census of Employment and Wages (QCEW) data, provided by the U.S. Bureau of Labor Statistics at https://www.bls.gov/cew/. The datasets retrieved and processed in this notebook contain detailed employment statistics, including the number of establishments, employment levels, total quarterly wages, and more, broken down by industry and ownership sectors for each county, the metadata is available at: https://www.bls.gov/cew/additional-resources/open-data/csv-data-slices.htm. This notebook specifically focuses on extracting data for a defined set of counties and years within a user specified lists, and either annual or quarterly data is collected based on user specification. See the Parameters section below to select the variables to be included in the extract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a11184-b7bd-40d3-8eb0-100aa34c9067",
   "metadata": {},
   "source": [
    "### Process Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b58ed3-5121-40c9-9bb8-b32592ff2025",
   "metadata": {},
   "source": [
    "The process carried out by this workflow can be described as follows:\n",
    "  - Users specify which years, quarters, and regions they are interested in analyzing through the script's parameter settings. \n",
    "  - The script accesses the QCEW data through the BLS' API. This interface automaticaly retrieves QCEW datasets based on specified parameters: year(s), quarter(s), and area code(s) (FIPS codes for counties).\n",
    "  - Once downloaded, the data undergoes a series of processing steps to format it correctly for analysis. This includes trimming unnecessary characters and converting data types where necessary.\n",
    "  - For each county within the specified region and for each year and/or quarter selected, the script generates a CSV file.\n",
    "  - With each CSV file, a .schema.yaml file is generated. This YAML (YAML Ain't Markup Language) file provides a human-readable schema, defining the structure, data types, and descriptions of the CSV file's columns based on the Frictionless Data specifications at https://frictionlessdata.io/. This schema ensures data consistency and aids in validation.\n",
    "  - Similarly, a .resource.yaml file is created for each dataset, following the Frictionless Data Resource specification at https://framework.frictionlessdata.io/docs/framework/resource.html. This file includes metadata about the CSV file, such as its name, path, format, and the schema it conforms to, as well as a hash code for integrity checking. Additionally, it contains descriptive information about the dataset and references to its source.\n",
    "  - The YAML files for schemas and resource descriptors are used to make data more usable by simplifying its publication and consumption. By adhering to Frictionless standards, the script ensures that the datasets it produces are easily shareable, validatable, and integrable into a wide range of data tools and platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047918d2-20c7-4666-a36b-680b748a9900",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b21b78-186c-48b4-b7be-6c732e2ed72f",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a42085-1d08-4c11-8cbc-c37ec75d7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import frictionless\n",
    "import sys\n",
    "sys.path.append(os.path.normpath(\"../morpc-common\"))\n",
    "import morpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36172b05-77df-44c7-9655-b62f12a512a2",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229008cc-df83-4783-9c5f-8a3a31c1ac63",
   "metadata": {},
   "source": [
    "#### User-specified Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a1415f-d64e-43b2-8797-021887a5c2da",
   "metadata": {},
   "source": [
    "This section is for user-specified parameters to define the scope of data retrieval: years, regions (via FIPS codes), and whether the data should be annual or quarterly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f0e27a6-37e1-4c0d-b227-147ba9494e2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for MORPC 15-County region only\n"
     ]
    }
   ],
   "source": [
    "# These parameters are intended for the user to edit based on the specific analysis requirements.\n",
    "\n",
    "# Define years for data collection\n",
    "YEARS_PARAMETER = [\"2020\"]                                  # List of years: 2020\n",
    "# YEARS_PARAMETER = [\"2018\" ,\"2019\", \"2020\", \"2021\", \"2022\"]  # List of years: 2018-2022\n",
    "\n",
    "# List of Census GEOIDs for counties to be included in data extract, default MORPC-15\n",
    "# COUNTY_CODES = [\"39041\",\"39049\"]                          # List of GEOIDs for a few specific counties\n",
    "COUNTY_CODES = morpc.countyLookup().list_ids()              # GEOIDs for all counties in the MORPC 15-County Region\n",
    "\n",
    "\n",
    "# Annual and Quarter codes for looping\n",
    "# The user can swtich to specify whether to fetch annual or quarterly data.\n",
    "QUARTERS = [\"a\"] # For annual data analysis.\n",
    "#QUARTERS = [\"1\", \"2\", \"3\", \"4\"] # For quarterly data analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fbb025-d18d-404f-8448-9e94c4528e6a",
   "metadata": {},
   "source": [
    "#### Static parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead572ea-3403-4260-b360-f54787ab5775",
   "metadata": {},
   "source": [
    "This section defines static parameters such as input and output directories, schema file names and paths, and a documentation URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24960b3a-13aa-4927-9764-1f0c80259585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "INPUT_DIR = \"./input_data\"\n",
    "OUTPUT_DIR = \"./output_data\"\n",
    "\n",
    "# Define quarterly and annual schema directories from local copies\n",
    "QUARTERLY_TABLE_SCHEMA_FILENAME = \"morpc-qcew-quarterly.schema.yaml\"\n",
    "QUARTERLY_TABLE_SCHEMA_PATH = os.path.join(OUTPUT_DIR, QUARTERLY_TABLE_SCHEMA_FILENAME)\n",
    "ANNUAL_TABLE_SCHEMA_FILENAME = \"morpc-qcew-annual.schema.yaml\"\n",
    "ANNUAL_TABLE_SCHEMA_PATH = os.path.join(OUTPUT_DIR, ANNUAL_TABLE_SCHEMA_FILENAME)\n",
    "\n",
    "# Documentation URL for the QCEW data - static because it points to the general documentation page\n",
    "QCEW_TABLE_DOC_URL=\"https://www.bls.gov/cew/additional-resources/open-data/csv-data-slices.htm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac029a4-3143-43cf-8d2f-f07c24e5ad01",
   "metadata": {},
   "source": [
    "### Define Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d69206-94e8-486c-a18a-8db6020dbac4",
   "metadata": {},
   "source": [
    "This section establishes the naming convention and paths for temporary data files, schema files, and resource files that will be generated and saved by the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f032f1-ffd2-4d2f-a220-a8a7fda08550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data files will be saved as: ./output_data\\morpc-qcew_{year}_{qtr}_{region}.csv\n",
      "Schema files will be saved as: ./output_data\\morpc-qcew_{year}_{qtr}_{region}.csv\n",
      "Resource files will be saved as: ./output_data\\morpc-qcew_{year}_{qtr}_{region}.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Data files will be saved as: {}\".format(os.path.join(OUTPUT_DIR, \"morpc-qcew_{year}_{qtr}_{region}.csv\")))\n",
    "print(\"Schema files will be saved as: {}\".format(os.path.join(OUTPUT_DIR, \"morpc-qcew_{year}_{qtr}_{region}.csv\")))\n",
    "print(\"Resource files will be saved as: {}\".format(os.path.join(OUTPUT_DIR, \"morpc-qcew_{year}_{qtr}_{region}.csv\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d42ed-2db8-4d2f-a131-684e3af59354",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e04330d-4099-4931-8670-bf30e4abe169",
   "metadata": {},
   "source": [
    "Based on user-set parameters, this section defines functions that retreive data frames, which are cleaned and saved as \".csv\" along with generated \".yaml\" schema and resource files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc21451-cd68-412a-bbc7-40b35ebf12cc",
   "metadata": {},
   "source": [
    "### Calling API and Creating Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34329eaf-2a44-4896-8fd8-6d9dee6fa160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qcewGetAreaDataPandas(year, qtr, area):\n",
    "    \"\"\"\n",
    "    Fetches QCEW area data for a specific year, quarter, and area using pandas.read_csv().\n",
    "    Parameters:\n",
    "        year (str): The year for which to fetch data.\n",
    "        qtr (str): The quarter ('1', '2', '3', '4', or 'a' for annual data).\n",
    "        area (str): The area code (FIPS code) for which to fetch data.\n",
    "    Returns:\n",
    "        DataFrame: A pandas DataFrame containing the fetched data, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    # Construct the URL based on function parameters\n",
    "    url_template = \"https://data.bls.gov/cew/data/api/{year}/{qtr}/area/{area}.csv\"\n",
    "    url = url_template.format(year=year, qtr=qtr.lower(), area=area.upper())\n",
    "\n",
    "    try:\n",
    "        # Attempt to read the CSV data directly into a pandas DataFrame\n",
    "        df = pd.read_csv(url)\n",
    "        return df\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"No data returned from the API.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047e2a3-e3ab-47cd-9cec-cab0573643bc",
   "metadata": {},
   "source": [
    "### Cleaning Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d04de9-9200-40b4-ae2e-c2f724542e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Cleans the input DataFrame by removing unnecessary characters from strings.\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to clean.\n",
    "    Returns:\n",
    "        DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Strip '\"' from column names if they exist\n",
    "    df.columns = df.columns.str.replace('\"', '')\n",
    "\n",
    "    # Apply the same stripping for all string columns in the DataFrame\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        df[col] = df[col].str.strip('\"')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441fcc2b-75a9-4d5d-8987-bcb183754c2b",
   "metadata": {},
   "source": [
    "### Creating data, schema, and resource file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44f3c451-cfce-4381-9f99-daec853fecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_paths(year, qtr, region):\n",
    "    \"\"\"\n",
    "    Creates and returns file paths for the data CSV, schema YAML, and resource YAML based on specified parameters.\n",
    "    Parameters:\n",
    "        year (str): The year of the data.\n",
    "        qtr (str): The quarter or 'a' for annual data.\n",
    "        region (str): The region code (FIPS code).\n",
    "    Returns:\n",
    "        dict: A dictionary containing paths for the data file, resource file, and schema file.\n",
    "    \"\"\"\n",
    "    TEMP_TABLE_NAME = f\"morpc-qcew-{year}-{qtr}-{region}.csv\"\n",
    "    TEMP_TABLE_PATH = os.path.join(OUTPUT_DIR, TEMP_TABLE_NAME)\n",
    "    TEMP_TABLE_RESOURCE_NAME = f\"morpc-qcew-{year}-{qtr}-{region}.resource.yaml\"\n",
    "    TEMP_TABLE_RESOURCE_PATH = os.path.join(OUTPUT_DIR, TEMP_TABLE_RESOURCE_NAME)\n",
    "\n",
    "\n",
    "    if qtr == \"a\":\n",
    "        schemaPath = ANNUAL_TABLE_SCHEMA_PATH  # Use the annual data schema path\n",
    "    else:\n",
    "        schemaPath = QUARTERLY_TABLE_SCHEMA_PATH  # Use a different schema path for non-annual data\n",
    "\n",
    "    \n",
    "    # Return paths\n",
    "    return {\n",
    "        \"data_path\": TEMP_TABLE_PATH,\n",
    "        \"resource_path\": TEMP_TABLE_RESOURCE_PATH,\n",
    "        \"schema_path\":schemaPath,\n",
    "    }  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a14850-34f4-482b-81ae-5ea9fa9192cf",
   "metadata": {},
   "source": [
    "### Saves data, schema, and resource files for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33824004-58d7-44d3-8658-548cc34863b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportDataResourceComponents(data, dataPath, schemaPath, resourcePath, year, region,qtr):\n",
    "    \"\"\"\n",
    "    Saves the given DataFrame to a CSV file and generates corresponding schema and resource YAML files.\n",
    "    Parameters:\n",
    "        data (DataFrame): The DataFrame to save.\n",
    "        dataPath (str): Path for the CSV file.\n",
    "        schemaPath (str): Path for the schema YAML file.\n",
    "        resourcePath (str): Path for the resource YAML file.\n",
    "        year (str): Year of the data.\n",
    "        region (str): Region code (FIPS code).\n",
    "        qtr (str): Quarter or 'a' for annual data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use absolute paths for validation\n",
    "    abs_dataPath = os.path.abspath(dataPath)\n",
    "    \n",
    "    # Load the schema from the YAML file\n",
    "    with open(schemaPath, 'r') as file:\n",
    "        schema = yaml.safe_load(file)\n",
    "\n",
    "    # Save the schema to a new .schema.yaml file in the same directory as the resource file\n",
    "    new_schemaPath = resourcePath.replace('.resource.yaml', '.schema.yaml')\n",
    "    with open(new_schemaPath, 'w') as file:\n",
    "        yaml.safe_dump(schema, file, sort_keys=False)\n",
    "    print(f\"Schema file written to {new_schemaPath}\")\n",
    "\n",
    "    acsResource = {\n",
    "      \"profile\": \"tabular-data-resource\",\n",
    "      \"name\": os.path.basename(dataPath).replace(\".csv\",\"\").lower(),\n",
    "      \"path\": os.path.basename(abs_dataPath),\n",
    "      \"title\": f\"Quarterly Census of Employment and Wages data {year}-{region}-{qtr}\",\n",
    "      \"description\": f\"Quarterly Census of Employment and Wages data for {region} in {qtr} of {year}.\",\n",
    "      \"format\": \"csv\",\n",
    "      \"mediatype\": \"text/csv\",\n",
    "      \"encoding\": \"utf-8\",\n",
    "      \"bytes\": os.path.getsize(dataPath),\n",
    "      \"hash\": morpc.md5(dataPath),\n",
    "      \"rows\": data.shape[0],\n",
    "      \"columns\": data.shape[1],    \n",
    "      \"schema\": schema,\n",
    "      \"sources\": [{\n",
    "          \"title\": \"Quarterly Census of Employment and Wages, U.S. Bureau of Labor Statistics\",\n",
    "          \"path\": QCEW_TABLE_DOC_URL\n",
    "      }]\n",
    "    }\n",
    "\n",
    "    # Create the resource object\n",
    "    resource = frictionless.Resource(acsResource)\n",
    "\n",
    "    print(\"Writing resource file to {}\".format(resourcePath))\n",
    "    dummy = resource.to_yaml(resourcePath)\n",
    "    \n",
    "    print(\"Validating resource on disk (including data and schema). This may take some time.\")\n",
    "    resourceOnDisk = frictionless.Resource(resourcePath)\n",
    "    results = resourceOnDisk.validate()\n",
    "    if(results.valid):\n",
    "        print(\"Resource is valid\\n\")\n",
    "    else:\n",
    "        print(\"ERROR: Resource is NOT valid. Errors follow.\\n\")\n",
    "        print(results)\n",
    "        raise RuntimeError\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63835a44-dd9a-4cc3-b6fe-40c5a86b19bf",
   "metadata": {},
   "source": [
    "## Main code for iterating through each year, region, and qtr combination for data, resource, and schema files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2082e19-9aae-4290-b14d-bea64f93db22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data to ./output_data\\morpc-qcew-2020-a-39041.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39041.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39041.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39045.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39045.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39045.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39047.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39047.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39047.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39049.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39049.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39049.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39073.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39073.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39073.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39083.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39083.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39083.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39089.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39089.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39089.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39091.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39091.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39091.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39097.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39097.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39097.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39101.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39101.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39101.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39117.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39117.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39117.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39127.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39127.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39127.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39129.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39129.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39129.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39141.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39141.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39141.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "Writing data to ./output_data\\morpc-qcew-2020-a-39159.csv\n",
      "Schema file written to ./output_data\\morpc-qcew-2020-a-39159.schema.yaml\n",
      "Writing resource file to ./output_data\\morpc-qcew-2020-a-39159.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Iterates over specified years, regions, and quarters, retrieves and processes data, and saves it along with schema and resource files.\n",
    "Parameters:\n",
    "    years (list): List of years to process in YEARS_PARAMETER\n",
    "    regions (list): List of region codes (FIPS codes) to process in COUNTY_CODES\n",
    "    qtrs (list): List of quarters [1,2,3,4] or [a] for annual data.\n",
    "\"\"\"\n",
    "for year in YEARS_PARAMETER:\n",
    "    for region in COUNTY_CODES:\n",
    "        for qtr in QUARTERS:\n",
    "\n",
    "            # Receive paths from generate_file_paths\n",
    "            paths = generate_file_paths(year, qtr, region)\n",
    "            temp_data = qcewGetAreaDataPandas(str(year), qtr, region)\n",
    "            \n",
    "            if temp_data is not None:  # Check if data is not None before proceeding\n",
    "                temp_df = clean_data(temp_data)\n",
    "                print(\"Writing data to {}\".format(paths[\"data_path\"]))\n",
    "                temp_df.to_csv(paths[\"data_path\"], index=False)\n",
    "                exportDataResourceComponents(temp_df, paths[\"data_path\"], paths[\"schema_path\"], paths[\"resource_path\"], year, region, qtr)\n",
    "            else:\n",
    "                print(f\"No data available for {year}, {qtr}, {region}\")\n",
    "                \n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed6a838-e8c7-4af7-97bd-1397c2125f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
