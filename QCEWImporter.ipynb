{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0265a124-87b8-4d00-a464-a43292974a65",
   "metadata": {},
   "source": [
    "# Quarterly Census of Employment and Wages (QCEW) Data Importer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec248bf1-54ee-40c7-8302-501b5e753630",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df1258-4c7a-4f1a-b183-05a28a9efbdf",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is designed to automate the retrieval and processing of the Quarterly Census of Employment and Wages (QCEW) data, provided by the [U.S. Bureau of Labor Statistics](https://www.bls.gov/cew/) . The datasets retrieved and processed in this notebook contain detailed employment statistics, including the number of establishments, employment levels, total quarterly wages, and more, broken down by industry and ownership sectors for each county, as defined by the [technical documentation](https://www.bls.gov/cew/additional-resources/open-data/csv-data-slices.htm). This notebook specifically focuses on extracting data for a defined set of counties and years within a user specified lists, and either annual or quarterly data is collected based on user specification. See the Parameters section below to select the variables to be included in the extract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a11184-b7bd-40d3-8eb0-100aa34c9067",
   "metadata": {},
   "source": [
    "### Process Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b58ed3-5121-40c9-9bb8-b32592ff2025",
   "metadata": {},
   "source": [
    "The process carried out by this workflow can be described as follows:\n",
    "  - Users specify which years, quarters, and regions they are interested in analyzing through the script's parameter settings. \n",
    "  - The script accesses the QCEW data through the BLS' API. This interface automaticaly retrieves QCEW datasets based on specified parameters: year(s), quarter(s), and area code(s) (FIPS codes for counties).\n",
    "  - Once downloaded, the data undergoes a series of processing steps to format it correctly for analysis. This includes trimming unnecessary characters and converting data types where necessary.\n",
    "  - For each county within the specified region and for each year and/or quarter selected, the script generates a CSV file.\n",
    "  - With each CSV file, a .schema.yaml file is generated. This YAML (YAML Ain't Markup Language) file provides a human-readable schema, defining the structure, data types, and descriptions of the CSV file's columns based on the [Frictionless Data specifications]( https://frictionlessdata.io/). This schema ensures data consistency and aids in validation.\n",
    "  - Similarly, a .resource.yaml file is created for each dataset, following the [Frictionless Data Resource specification](https://framework.frictionlessdata.io/docs/framework/resource.html). This file includes metadata about the CSV file, such as its name, path, format, and the schema it conforms to, as well as a hash code for integrity checking. Additionally, it contains descriptive information about the dataset and references to its source.\n",
    "  - The YAML files for schemas and resource descriptors are used to make data more usable by simplifying its publication and consumption. By adhering to Frictionless standards, the script ensures that the datasets it produces are easily shareable, validatable, and integrable into a wide range of data tools and platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047918d2-20c7-4666-a36b-680b748a9900",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b21b78-186c-48b4-b7be-6c732e2ed72f",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f3a42085-1d08-4c11-8cbc-c37ec75d7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import frictionless\n",
    "import sys\n",
    "sys.path.append(os.path.normpath(\"../morpc-common\"))\n",
    "import morpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36172b05-77df-44c7-9655-b62f12a512a2",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229008cc-df83-4783-9c5f-8a3a31c1ac63",
   "metadata": {},
   "source": [
    "#### User-specified Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a1415f-d64e-43b2-8797-021887a5c2da",
   "metadata": {},
   "source": [
    "This section is for user-specified parameters to define the scope of data retrieval: years, regions (via FIPS codes), and whether the data should be annual or quarterly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5f0e27a6-37e1-4c0d-b227-147ba9494e2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for MORPC 15-County region only\n"
     ]
    }
   ],
   "source": [
    "# These parameters are intended for the user to edit based on the specific analysis requirements.\n",
    "\n",
    "# Define years for data collection\n",
    "YEARS_PARAMETER = [\"2020\"]                                  # List of years: 2020\n",
    "# YEARS_PARAMETER = [\"2018\" ,\"2019\", \"2020\", \"2021\", \"2022\"]  # List of years: 2018-2022\n",
    "\n",
    "# List of Census GEOIDs for counties to be included in data extract, default MORPC-15\n",
    "# COUNTY_CODES = [\"39041\",\"39049\"]                          # List of GEOIDs for a few specific counties\n",
    "COUNTY_CODES = morpc.countyLookup().list_ids()              # GEOIDs for all counties in the MORPC 15-County Region\n",
    "\n",
    "\n",
    "# Annual and Quarter codes for looping\n",
    "# The user can swtich to specify whether to fetch annual or quarterly data.\n",
    "#QUARTERS = [\"a\"] # For annual data analysis.\n",
    "QUARTERS = [\"1\", \"2\", \"3\", \"4\"] # For quarterly data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fbb025-d18d-404f-8448-9e94c4528e6a",
   "metadata": {},
   "source": [
    "#### Static parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead572ea-3403-4260-b360-f54787ab5775",
   "metadata": {},
   "source": [
    "This section defines static parameters such as input and output directories, schema file names and paths, and a documentation URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "24960b3a-13aa-4927-9764-1f0c80259585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "OUTPUT_DIR = \"./output_data\"\n",
    "\n",
    "# Define quarterly and annual schema directories from local copies\n",
    "QUARTERLY_TABLE_SCHEMA_FILENAME = \"morpc-qcew-quarterly.schema.yaml\"\n",
    "QUARTERLY_TABLE_SCHEMA_PATH = os.path.join(OUTPUT_DIR, QUARTERLY_TABLE_SCHEMA_FILENAME)\n",
    "ANNUAL_TABLE_SCHEMA_FILENAME = \"morpc-qcew-annual.schema.yaml\"\n",
    "ANNUAL_TABLE_SCHEMA_PATH = os.path.join(OUTPUT_DIR, ANNUAL_TABLE_SCHEMA_FILENAME)\n",
    "\n",
    "# Documentation URL for the QCEW data - static because it points to the general documentation page\n",
    "QCEW_TABLE_DOC_URL=\"https://www.bls.gov/cew/additional-resources/open-data/csv-data-slices.htm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e39d8b5-57fa-4f7c-934d-226debb2d10f",
   "metadata": {},
   "source": [
    "### Define Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cc2531-e502-4458-93b7-83a1d56a106f",
   "metadata": {},
   "source": [
    "This code prints the location of the existing .yaml schemas for use in the resource files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "352563de-78a0-4ff3-906e-7531b37a30fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual schema file stored in: ./output_data\\morpc-qcew-annual.schema.yaml\n",
      "Quarterly schema file stored in: ./output_data\\morpc-qcew-quarterly.schema.yaml\n"
     ]
    }
   ],
   "source": [
    "print(\"Annual schema file stored in: {}\".format(ANNUAL_TABLE_SCHEMA_PATH))\n",
    "print(\"Quarterly schema file stored in: {}\".format(QUARTERLY_TABLE_SCHEMA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac029a4-3143-43cf-8d2f-f07c24e5ad01",
   "metadata": {},
   "source": [
    "### Define Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d69206-94e8-486c-a18a-8db6020dbac4",
   "metadata": {},
   "source": [
    "This section establishes the naming convention and paths for temporary data files, schema files, and resource files that will be generated and saved by the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "53f032f1-ffd2-4d2f-a220-a8a7fda08550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data files will be saved as: ./output_data\\morpc-qcew-{year}-{qtr}-{region}.csv\n",
      "Resource files will be saved as: ./output_data\\morpc-qcew-{year}-{qtr}-{region}.resource.yaml\n"
     ]
    }
   ],
   "source": [
    "print(\"Data files will be saved as: {}\".format(os.path.join(OUTPUT_DIR, \"morpc-qcew-{year}-{qtr}-{region}.csv\")))\n",
    "print(\"Resource files will be saved as: {}\".format(os.path.join(OUTPUT_DIR, \"morpc-qcew-{year}-{qtr}-{region}.resource.yaml\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d42ed-2db8-4d2f-a131-684e3af59354",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e04330d-4099-4931-8670-bf30e4abe169",
   "metadata": {},
   "source": [
    "Based on user-set parameters, this section defines functions that retreive data frames, which are cleaned and saved as \".csv\" along with generated \".yaml\" schema and resource files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc21451-cd68-412a-bbc7-40b35ebf12cc",
   "metadata": {},
   "source": [
    "### Calling API and Creating Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "34329eaf-2a44-4896-8fd8-6d9dee6fa160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qcewGetAreaDataPandas(year, qtr, area):\n",
    "    \"\"\"\n",
    "    Fetches QCEW area data for a specific year, quarter, and area using pandas.read_csv().\n",
    "    Parameters:\n",
    "        year (str): The year for which to fetch data.\n",
    "        qtr (str): The quarter ('1', '2', '3', '4', or 'a' for annual data).\n",
    "        area (str): The area code (FIPS code) for which to fetch data.\n",
    "    Returns:\n",
    "        DataFrame: A pandas DataFrame containing the fetched data, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    # Construct the URL based on function parameters\n",
    "    url_template = \"https://data.bls.gov/cew/data/api/{year}/{qtr}/area/{area}.csv\"\n",
    "    url = url_template.format(year=year, qtr=qtr.lower(), area=area.upper())\n",
    "\n",
    "    try:\n",
    "        # Attempt to read the CSV data directly into a pandas DataFrame\n",
    "        df = pd.read_csv(url)\n",
    "        return df\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"No data returned from the API.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047e2a3-e3ab-47cd-9cec-cab0573643bc",
   "metadata": {},
   "source": [
    "### Cleaning Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f7d04de9-9200-40b4-ae2e-c2f724542e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Cleans the input DataFrame by removing unnecessary characters from strings.\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to clean.\n",
    "    Returns:\n",
    "        DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Strip '\"' from column names if they exist\n",
    "    df.columns = df.columns.str.replace('\"', '')\n",
    "\n",
    "    # Apply the same stripping for all string columns in the DataFrame\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        df[col] = df[col].str.strip('\"')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441fcc2b-75a9-4d5d-8987-bcb183754c2b",
   "metadata": {},
   "source": [
    "### Creating data, schema, and resource file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "44f3c451-cfce-4381-9f99-daec853fecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_paths(year, qtr, region):\n",
    "    \"\"\"\n",
    "    Creates and returns file paths for the data CSV, schema YAML, and resource YAML based on specified parameters.\n",
    "    Parameters:\n",
    "        year (str): The year of the data.\n",
    "        qtr (str): The quarter or 'a' for annual data.\n",
    "        region (str): The region code (FIPS code).\n",
    "    Returns:\n",
    "        dict: A dictionary containing paths for the data file, resource file, and schema file.\n",
    "    \"\"\"\n",
    "    TEMP_TABLE_NAME = f\"morpc-qcew-{year}-{qtr}-{region}.csv\"\n",
    "    TEMP_TABLE_PATH = os.path.join(OUTPUT_DIR, TEMP_TABLE_NAME)\n",
    "    TEMP_TABLE_RESOURCE_NAME = f\"morpc-qcew-{year}-{qtr}-{region}.resource.yaml\"\n",
    "    TEMP_TABLE_RESOURCE_PATH = os.path.join(OUTPUT_DIR, TEMP_TABLE_RESOURCE_NAME)\n",
    "\n",
    "\n",
    "    if qtr == \"a\":\n",
    "        schemaPath = ANNUAL_TABLE_SCHEMA_PATH  # Use the annual data schema path\n",
    "    else:\n",
    "        schemaPath = QUARTERLY_TABLE_SCHEMA_PATH  # Use a different schema path for non-annual data\n",
    "\n",
    "    \n",
    "    # Return paths\n",
    "    return {\n",
    "        \"data_path\": TEMP_TABLE_PATH,\n",
    "        \"resource_path\": TEMP_TABLE_RESOURCE_PATH,\n",
    "        \"schema_path\":schemaPath,\n",
    "    }  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a14850-34f4-482b-81ae-5ea9fa9192cf",
   "metadata": {},
   "source": [
    "### Saves data, schema, and resource files for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "33824004-58d7-44d3-8658-548cc34863b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_quarter(qtr):\n",
    "    \"\"\"Format quarter for readability.\"\"\"\n",
    "    quarters = {\"1\": \"Q1\", \"2\": \"Q2\", \"3\": \"Q3\", \"4\": \"Q4\", \"a\" : \"Annual\"}\n",
    "    return quarters.get(qtr, qtr)\n",
    "\n",
    "def exportDataResourceComponents(data, dataPath, schemaPath, resourcePath, year, region,qtr, county_lookup):\n",
    "    \"\"\"\n",
    "    Saves the given DataFrame to a CSV file and generates corresponding schema and resource YAML files.\n",
    "    Parameters:\n",
    "        data (DataFrame): The DataFrame to save.\n",
    "        dataPath (str): Path for the CSV file.\n",
    "        schemaPath (str): Path for the schema YAML file.\n",
    "        resourcePath (str): Path for the resource YAML file.\n",
    "        year (str): Year of the data.\n",
    "        region (str): Region code (FIPS code).\n",
    "        qtr (str): Quarter or 'a' for annual data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use absolute paths for validation\n",
    "    abs_dataPath = os.path.abspath(dataPath)\n",
    "    abs_schemaPath = os.path.abspath(schemaPath) \n",
    "\n",
    "    # Load the schema from the YAML file\n",
    "    with open(schemaPath, 'r') as file:\n",
    "        schema = yaml.safe_load(file)\n",
    "\n",
    "    # Convert region from GEOID to county name\n",
    "    region_name = county_lookup.get_name(region)\n",
    "\n",
    "    # Format quarter for readability\n",
    "    formatted_qtr = format_quarter(qtr)\n",
    "\n",
    "    # Update title and description with the county name\n",
    "    title = f\"QCEW Data for {region_name} County, {year}, {formatted_qtr}\"\n",
    "    description = f\"{formatted_qtr} employment and wage data for {region_name} county in {year}, derived from the U.S. Bureau of Labor Statistics.\"\n",
    "\n",
    "    \n",
    "    acsResource = {\n",
    "      \"profile\": \"tabular-data-resource\",\n",
    "      \"name\": os.path.basename(dataPath).replace(\".csv\",\"\").lower(),\n",
    "      \"path\": os.path.basename(abs_dataPath),\n",
    "      \"title\": title,\n",
    "      \"description\": description,\n",
    "      \"format\": \"csv\",\n",
    "      \"mediatype\": \"text/csv\",\n",
    "      \"encoding\": \"utf-8\",\n",
    "      \"bytes\": os.path.getsize(dataPath),\n",
    "      \"hash\": morpc.md5(dataPath),\n",
    "      \"rows\": data.shape[0],\n",
    "      \"columns\": data.shape[1],    \n",
    "      \"schema\": schema,\n",
    "      \"sources\": [{\n",
    "          \"title\": \"Quarterly Census of Employment and Wages, U.S. Bureau of Labor Statistics\",\n",
    "          \"path\": QCEW_TABLE_DOC_URL\n",
    "      }]\n",
    "    }\n",
    "\n",
    "    # Create the resource object\n",
    "    resource = frictionless.Resource(acsResource)\n",
    "\n",
    "    print(\"Writing resource file to {}\".format(resourcePath))\n",
    "    dummy = resource.to_yaml(resourcePath)\n",
    "    \n",
    "    print(\"SCHEMA data to {}\".format(schemaPath))\n",
    "    \n",
    "    print(\"Validating resource on disk (including data and schema). This may take some time.\")\n",
    "    resourceOnDisk = frictionless.Resource(resourcePath)\n",
    "    results = resourceOnDisk.validate()\n",
    "    if(results.valid):\n",
    "        print(\"Resource is valid\\n\")\n",
    "    else:\n",
    "        print(\"ERROR: Resource is NOT valid. Errors follow.\\n\")\n",
    "        print(results)\n",
    "        raise RuntimeError\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63835a44-dd9a-4cc3-b6fe-40c5a86b19bf",
   "metadata": {},
   "source": [
    "## Main code for iterating through each year, region, and qtr combination for data, resource, and schema files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d2082e19-9aae-4290-b14d-bea64f93db22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for Ohio counties only\n",
      "Writing data to ./output_data\\morpc-qcew-2020-1-39041.csv\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './output_data\\\\morpc-qcew-2020-1-39041.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[176], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m     temp_df \u001b[38;5;241m=\u001b[39m clean_data(temp_data)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting data to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mtemp_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     exportDataResourceComponents(temp_df, paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m\"\u001b[39m], paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema_path\u001b[39m\u001b[38;5;124m\"\u001b[39m], paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresource_path\u001b[39m\u001b[38;5;124m\"\u001b[39m], year, region, qtr, county_lookup)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\newvirt\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\newvirt\\Lib\\site-packages\\pandas\\core\\generic.py:3964\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3953\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3955\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3956\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3957\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3961\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3962\u001b[0m )\n\u001b[1;32m-> 3964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3967\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\newvirt\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\newvirt\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\newvirt\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './output_data\\\\morpc-qcew-2020-1-39041.csv'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Iterates over specified years, regions, and quarters, retrieves and processes data, and saves it along with schema and resource files.\n",
    "Parameters:\n",
    "    years (list): List of years to process in YEARS_PARAMETER\n",
    "    regions (list): List of region codes (FIPS codes) to process in COUNTY_CODES\n",
    "    qtrs (list): List of quarters [1,2,3,4] or [a] for annual data.\n",
    "\"\"\"\n",
    "# Instantiate countyLookup with a scope relevant to your data\n",
    "county_lookup = morpc.countyLookup(scope=\"ohio\")  # Adjust scope as needed\n",
    "\n",
    "for year in YEARS_PARAMETER:\n",
    "    for region in COUNTY_CODES:\n",
    "        for qtr in QUARTERS:\n",
    "\n",
    "            # Receive paths from generate_file_paths\n",
    "            paths = generate_file_paths(year, qtr, region)\n",
    "            temp_data = qcewGetAreaDataPandas(str(year), qtr, region)\n",
    "            \n",
    "            if temp_data is not None:  # Check if data is not None before proceeding\n",
    "                temp_df = clean_data(temp_data)\n",
    "                print(\"Writing data to {}\".format(paths[\"data_path\"]))\n",
    "                temp_df.to_csv(paths[\"data_path\"], index=False)\n",
    "                exportDataResourceComponents(temp_df, paths[\"data_path\"], paths[\"schema_path\"], paths[\"resource_path\"], year, region, qtr, county_lookup)\n",
    "            else:\n",
    "                print(f\"No data available for {year}, {qtr}, {region}\")\n",
    "                \n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed6a838-e8c7-4af7-97bd-1397c2125f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
